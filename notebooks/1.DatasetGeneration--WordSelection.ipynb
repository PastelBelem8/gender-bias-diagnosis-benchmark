{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca1587b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import pickle, time, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce3ff16",
   "metadata": {},
   "source": [
    "# Dataset generation - Stage 1.  Word Selection\n",
    "\n",
    "This notebook represents the very first step in our data generation pipeline. Since our goal is to create a dataset that is gender-invariant and free of gender co-occurring words, we will have to make sure that the words we use to bootstrap the generation of our dataset are, themselves, abiding by the properties we defined. In particular, we want to make sure that the words selected by our procedure satisfy the following property:\n",
    "\n",
    "$-\\epsilon \\leq \\texttt{PMI}(w, \\texttt{\"she\"}) - \\texttt{PMI}(w, \\texttt{\"he\"}) \\leq \\epsilon $, where $w$ is a word in the vocabulary and $\\epsilon$ is a limit on how much skewed a word can be towards one of the gendered words. As detailed in the paper, we set $\\epsilon = 0.263$.\n",
    "\n",
    "\n",
    "\n",
    "The notebook is organized as follows:\n",
    "1. Read the co-occurrence counts from PILE as well as the term-frequencies, as collected by [Razeghi et al (2022)](https://aclanthology.org/2022.emnlp-demos.39/).\n",
    "2. Preprocess the list of words to remove non-English words.\n",
    "3. Preprocess the remaining words and remove rare words (e.g., words in the 20% percentile).\n",
    "4. Compute the $\\texttt{PMIDiff}(w) = \\texttt{PMI}(w, \\texttt{\"she\"}) - \\texttt{PMI}(w, \\texttt{\"he\"})$ value for every word $w$\n",
    "5. Sample a subset centered around the origin by sampling words that satisfy  $ -\\epsilon \\leq \\texttt{PMIDiff}(w) \\leq \\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6670096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory where to find the files\n",
    "DATA_DIR = \"/extra/ucinlp1/cbelem/bias-dataset-project\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c104f80",
   "metadata": {},
   "source": [
    "## 1. Load term counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fce49ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pkl_file(fp: str):\n",
    "    \"\"\"Wrapper to read pickled filepath.\"\"\"\n",
    "    print(\"Reading file at\", fp)\n",
    "    start = time.time()\n",
    "    with open(fp, 'rb') as tff:\n",
    "        data = pickle.load(tff)\n",
    "    end = time.time()\n",
    "    print(f\"Time to read file {(end-start)/60:.2f} min\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def read_original_coccurrence_files(parent_dir: str) -> dict: # 5GB\n",
    "    \"\"\"Wrapper to read the co-occurrence term count files from parent_dir.\"\"\"\n",
    "    return read_pkl_file(f\"{parent_dir}/all_co_words.pkl\")\n",
    "\n",
    "\n",
    "def read_original_tf_files(parent_dir) -> dict: # 16M\n",
    "    \"\"\"Wrapper to read the term-frequency file from parent_dir.\"\"\"\n",
    "    return read_pkl_file(f\"{parent_dir}/term_frequency.pkl\")\n",
    "\n",
    "\n",
    "def read_pmi_diff(filepath: str) -> pd.DataFrame: #1.9M\n",
    "    \"\"\"Read precomputed PMI difference file\"\"\"\n",
    "    # Read the PMI difference filepath\n",
    "    pmi_diff = {\"word\": [], \"pmi_diff\": []}\n",
    "    with open(filepath, \"rt\") as f:\n",
    "        for row in f:\n",
    "            word, _, val = row.rpartition(\",\")\n",
    "            pmi_diff[\"word\"].append(word)\n",
    "            pmi_diff[\"pmi_diff\"].append(float(val))\n",
    "    return pd.DataFrame(pmi_diff).sort_values(\"pmi_diff\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54077ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file at /extra/ucinlp1/cbelem/bias-dataset-project/term_frequency.pkl\n",
      "Time to read file 0.00 min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>counts</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>8547638016</td>\n",
       "      <td>0.065901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>*</td>\n",
       "      <td>2911636063</td>\n",
       "      <td>0.022448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>=</td>\n",
       "      <td>2693603408</td>\n",
       "      <td>0.020767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/</td>\n",
       "      <td>1842700323</td>\n",
       "      <td>0.014207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>696181955</td>\n",
       "      <td>0.005367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word      counts      freq\n",
       "0    -  8547638016  0.065901\n",
       "1    *  2911636063  0.022448\n",
       "2    =  2693603408  0.020767\n",
       "3    /  1842700323  0.014207\n",
       "4    2   696181955  0.005367"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Easier to lookup for word -> term frequency\n",
    "TERM_COUNTS_DICT = read_original_tf_files(DATA_DIR)\n",
    "TERM_COUNTS_TOTAL = sum(TERM_COUNTS_DICT.values())\n",
    "# Convert term counts into dataframe to add more metadata\n",
    "TERM_COUNTS_DF = pd.DataFrame(TERM_COUNTS_DICT.items(), columns=[\"word\", \"counts\"])\n",
    "\n",
    "total_counts = sum(TERM_COUNTS_DICT.values())\n",
    "\n",
    "# Add a relative frequency column\n",
    "TERM_COUNTS_DF[\"freq\"] = TERM_COUNTS_DF[\"counts\"].apply(lambda x: x / total_counts)\n",
    "TERM_COUNTS_DF.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4058b312",
   "metadata": {},
   "source": [
    "## Preprocessing data\n",
    "\n",
    "**Keeping English Alphabet words:**\n",
    "In this section, we wish to exclude numbers, punctuation, non-english words from the list of words. Therefore, a first preprocessing step we do is to exclude any word that is not fully created based on the English alphabet. We use Python's default functionality `str.isalpha` to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55e3940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.34% of the examples (out of 770874) belong to the English alphabet.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>counts</th>\n",
       "      <th>freq</th>\n",
       "      <th>isalpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>770857</th>\n",
       "      <td>subjectivization</td>\n",
       "      <td>2070</td>\n",
       "      <td>1.595946e-08</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770858</th>\n",
       "      <td>qtilde</td>\n",
       "      <td>2070</td>\n",
       "      <td>1.595946e-08</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770859</th>\n",
       "      <td>flavanoid</td>\n",
       "      <td>2070</td>\n",
       "      <td>1.595946e-08</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770860</th>\n",
       "      <td>tedisco</td>\n",
       "      <td>2070</td>\n",
       "      <td>1.595946e-08</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770861</th>\n",
       "      <td>schimperi</td>\n",
       "      <td>2070</td>\n",
       "      <td>1.595946e-08</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770865</th>\n",
       "      <td>yhw</td>\n",
       "      <td>2070</td>\n",
       "      <td>1.595946e-08</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770866</th>\n",
       "      <td>qopt</td>\n",
       "      <td>2070</td>\n",
       "      <td>1.595946e-08</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770867</th>\n",
       "      <td>echaban</td>\n",
       "      <td>2070</td>\n",
       "      <td>1.595946e-08</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770870</th>\n",
       "      <td>sulina</td>\n",
       "      <td>2070</td>\n",
       "      <td>1.595946e-08</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770873</th>\n",
       "      <td>fritzy</td>\n",
       "      <td>2070</td>\n",
       "      <td>1.595946e-08</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    word  counts          freq  isalpha\n",
       "770857  subjectivization    2070  1.595946e-08     True\n",
       "770858            qtilde    2070  1.595946e-08     True\n",
       "770859         flavanoid    2070  1.595946e-08     True\n",
       "770860           tedisco    2070  1.595946e-08     True\n",
       "770861         schimperi    2070  1.595946e-08     True\n",
       "770865               yhw    2070  1.595946e-08     True\n",
       "770866              qopt    2070  1.595946e-08     True\n",
       "770867           echaban    2070  1.595946e-08     True\n",
       "770870            sulina    2070  1.595946e-08     True\n",
       "770873            fritzy    2070  1.595946e-08     True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine whether the words belong to the english alphabet or not\n",
    "TERM_COUNTS_DF['isalpha'] = TERM_COUNTS_DF[\"word\"].apply(str.isalpha)\n",
    "\n",
    "english_alphabet = TERM_COUNTS_DF[\"isalpha\"].value_counts()[True]\n",
    "print(f'{english_alphabet/len(TERM_COUNTS_DF):.2%} of the examples',\n",
    "      f'(out of {len(TERM_COUNTS_DF)}) belong to the English alphabet.')\n",
    "\n",
    "# Drop words containing non-English alphabet characters\n",
    "TERM_COUNTS_DF = TERM_COUNTS_DF[TERM_COUNTS_DF[\"isalpha\"]]\n",
    "TERM_COUNTS_DF[TERM_COUNTS_DF[\"isalpha\"]].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab5b1c5",
   "metadata": {},
   "source": [
    "**Removing non-English words**: However, restricting to the English alphabet does not exclude other languages. For example, the spanish word \"echaban\" would be kept if we only applied the previous procedure. One hypothesis would be to remove the non-English words, using a language detector. However, this may also remove borrowed foreign words that are common in the English language, like _influenza_. \n",
    "\n",
    "Therefore, in the following cells, we will use a heuristic approach that keeps a word in `TERM_COUNTS_DF` if one of the following conditions is satisfied:\n",
    "\n",
    "1. The [fasttext](https://fasttext.cc/docs/en/unsupervised-tutorial.html) character-level language classifier predicts the word language to be English word with at least `ENGLISH_PRED_THRESHOLD`% confidence.\n",
    "2. There exists a sense definition for word $w$ in [WordNet](https://wordnet.princeton.edu/).\n",
    "\n",
    "\n",
    "Note: We experimented with [langdetect](https://pypi.org/project/langdetect/) library from Google as well, but it performs poorly when identifying individual words, e.g., mentions that _hello_ is not English. Leading to a large number of false negatives (i.e., claiming English words are non-English words). On the other hand, fasttext proved to be much better at this task. Besides, it also gives the confidence associated with the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b634502",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import fasttext\n",
    "except:\n",
    "    # Install fasttext\n",
    "    !pip install fasttext\n",
    "    import fasttext\n",
    "from typing import List, Tuple \n",
    "\n",
    "    \n",
    "FTEXT_MODEL_NAME = \"lid.176.bin\"\n",
    "# Download the language detection model (trained w/ 176 languages)\n",
    "if not os.path.isfile(FTEXT_MODEL_NAME):\n",
    "    !wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\n",
    "        \n",
    "# Load fasttext model\n",
    "FTEXT_MODEL = fasttext.load_model(FTEXT_MODEL_NAME)\n",
    "\n",
    "# Language threshold\n",
    "ENGLISH_PRED_THRESHOLD = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00fccffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.03% of the words are predicted to be English\n",
      "Number of unique predicted languages: 176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ft_pred_lang\n",
       "en     235132\n",
       "de      39083\n",
       "fr      36183\n",
       "it      33114\n",
       "es      30462\n",
       "        ...  \n",
       "rue         2\n",
       "sc          2\n",
       "av          1\n",
       "mai         1\n",
       "dty         1\n",
       "Name: count, Length: 176, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fasttext_predict(word: str, model):\n",
    "    \"\"\"Predicts the language using the specified fasttext model.\"\"\"\n",
    "    pred = model.predict(word, k=1)\n",
    "    return pred[0][0].replace(\"__label__\", \"\"), pred[1][0]\n",
    "\n",
    "\n",
    "# Determine whether words are english\n",
    "TERM_COUNTS_DF[\"ft_pred_lang\"], TERM_COUNTS_DF[\"ft_pred_conf\"] = zip(\n",
    "    *TERM_COUNTS_DF[\"word\"].apply(fasttext_predict, model=FTEXT_MODEL)\n",
    ")\n",
    "pred_eng_counts = TERM_COUNTS_DF[\"ft_pred_lang\"].value_counts()[\"en\"]\n",
    "print(f'{pred_eng_counts/len(TERM_COUNTS_DF):.2%} of the words are predicted to be English')\n",
    "print(f'Number of unique predicted languages: {TERM_COUNTS_DF[\"ft_pred_lang\"].nunique()}')\n",
    "TERM_COUNTS_DF[\"ft_pred_lang\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6948c6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wordnet_counts\n",
       "0    0.836202\n",
       "1    0.086968\n",
       "2    0.034485\n",
       "3    0.016211\n",
       "4    0.008566\n",
       "5    0.005259\n",
       "6    0.003246\n",
       "7    0.002385\n",
       "8    0.001419\n",
       "9    0.001085\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Count the number of wordnet senses\n",
    "TERM_COUNTS_DF[\"wordnet_counts\"] = TERM_COUNTS_DF[\"word\"].apply(lambda x: len(wordnet.synsets(x)))\n",
    "(TERM_COUNTS_DF[\"wordnet_counts\"].value_counts() / len(TERM_COUNTS_DF)).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ae447f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of non english words: 422635\n",
      "Examples of words dropped due to being dubbed not english according to our procedure...\n",
      "- aaaa\n",
      "- accountrepository\n",
      "- addrows\n",
      "- afsnit\n",
      "- akinci\n",
      "- allelements\n",
      "- amerigas\n",
      "- angkasa\n",
      "- anumit\n",
      "- aquarian\n",
      "- arrc\n",
      "- assignedto\n",
      "- aufgenommen\n",
      "- avicularia\n",
      "- bahcall\n",
      "- bartosz\n",
      "- beechey\n",
      "- bergey\n",
      "- biase\n",
      "- birkoff\n",
      "- bmpria\n",
      "- botos\n",
      "- brindado\n",
      "- buildactionmask\n",
      "- børnene\n",
      "- canalys\n",
      "- casciano\n",
      "- celebrazione\n",
      "- chaotique\n",
      "- chiều\n",
      "- cisi\n",
      "- cmpresult\n",
      "- comaroff\n",
      "- condotto\n",
      "- contextptr\n",
      "- cosechas\n",
      "- creveld\n",
      "- cuihao\n",
      "- códice\n",
      "- databse\n",
      "- deciziilor\n",
      "- demnach\n",
      "- despido\n",
      "- dichos\n",
      "- dischord\n",
      "- doces\n",
      "- doublevector\n",
      "- dtsq\n",
      "- décevoir\n",
      "- edendada\n",
      "- eisemann\n",
      "- emercoin\n",
      "- ennen\n",
      "- erasistratus\n",
      "- espanola\n",
      "- euroqol\n",
      "- expérimentations\n",
      "- farcry\n",
      "- fermor\n",
      "- finanzen\n",
      "- flug\n",
      "- forståelse\n",
      "- frii\n",
      "- fva\n",
      "- ganji\n",
      "- gelsolin\n",
      "- getaverage\n",
      "- ghazzali\n",
      "- globales\n",
      "- gosselin\n",
      "- grindr\n",
      "- gurmukh\n",
      "- halid\n",
      "- hastie\n",
      "- hellyer\n",
      "- hhz\n",
      "- hoffmaster\n",
      "- hrig\n",
      "- hyperimmune\n",
      "- identificado\n",
      "- ilumina\n",
      "- incorrecta\n",
      "- initwithtitle\n",
      "- intercon\n",
      "- ioma\n",
      "- isomonodromic\n",
      "- jacht\n",
      "- jenine\n",
      "- jov\n",
      "- kadangi\n",
      "- kartheiser\n",
      "- kepner\n",
      "- kinocilia\n",
      "- koilocytosis\n",
      "- kotli\n",
      "- kumppanuuden\n",
      "- lachend\n",
      "- lastblockhash\n",
      "- lehetne\n",
      "- libellants\n",
      "- lipoxins\n",
      "- lofi\n",
      "- luban\n",
      "- léonard\n",
      "- maiestie\n",
      "- manlam\n",
      "- marwan\n",
      "- mayorga\n",
      "- medrol\n",
      "- mercalli\n",
      "- mgfa\n",
      "- millimetric\n",
      "- mittenwald\n",
      "- moller\n",
      "- mosimann\n",
      "- mukono\n",
      "- mycarousel\n",
      "- nachhaltigen\n",
      "- następujących\n",
      "- nejprve\n",
      "- newtime\n",
      "- nivel\n",
      "- nonthyroidal\n",
      "- nsproxy\n",
      "- nó\n",
      "- odnr\n",
      "- olulist\n",
      "- ophuls\n",
      "- orys\n",
      "- oxana\n",
      "- panditji\n",
      "- partagée\n",
      "- pcloud\n",
      "- perfbitmmapdata\n",
      "- pgcs\n",
      "- pilachowski\n",
      "- plesiomorphic\n",
      "- polixenes\n",
      "- postavení\n",
      "- prawodawstwa\n",
      "- priemonės\n",
      "- projecteur\n",
      "- précis\n",
      "- puntualmente\n",
      "- qformat\n",
      "- qwerty\n",
      "- raphaelson\n",
      "- recebeu\n",
      "- regolare\n",
      "- repositorytype\n",
      "- revois\n",
      "- rionegro\n",
      "- ronald\n",
      "- rubripes\n",
      "- rønning\n",
      "- samobor\n",
      "- sayf\n",
      "- schwarzchild\n",
      "- seffner\n",
      "- sepoys\n",
      "- severní\n",
      "- shorenstein\n",
      "- simos\n",
      "- skollie\n",
      "- snížit\n",
      "- soruşturma\n",
      "- spli\n",
      "- stallcup\n",
      "- stillage\n",
      "- stuckey\n",
      "- sugababes\n",
      "- susurró\n",
      "- szf\n",
      "- talao\n",
      "- tbjg\n",
      "- tenmile\n",
      "- teyssier\n",
      "- tiene\n",
      "- tnum\n",
      "- torvald\n",
      "- trasformata\n",
      "- truchas\n",
      "- tutkimaan\n",
      "- ubijtsa\n",
      "- umuahia\n",
      "- updown\n",
      "- uttrakhand\n",
      "- vanning\n",
      "- venger\n",
      "- vetenskapliga\n",
      "- virtua\n",
      "- voornemens\n",
      "- vítkovice\n",
      "- webmin\n",
      "- wiik\n",
      "- wrapmode\n",
      "- xlstat\n",
      "- yitz\n",
      "- zapier\n",
      "- znači\n",
      "- çoğu\n",
      "- đã\n",
      "- επιπλέον\n",
      "- υψηλού\n",
      "- держава\n",
      "- линия\n",
      "- париже\n",
      "- ростом\n",
      "- уточнить\n",
      "- الحدود\n",
      "- هنا\n",
      "- 보다\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "150424"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def english_words_mask(df: pd.DataFrame, threshold) -> pd.DataFrame:\n",
    "    is_english = (df[\"ft_pred_lang\"] == \"en\") & (df[\"ft_pred_conf\"] > threshold)\n",
    "    is_in_wordnet = (is_english == False) & (df[\"wordnet_counts\"] > 0)\n",
    "    return (is_english | is_in_wordnet)\n",
    "\n",
    "\n",
    "IS_ENGLISH_MASK = english_words_mask(TERM_COUNTS_DF, ENGLISH_PRED_THRESHOLD)\n",
    "\n",
    "nonengl_terms_orig_pmi = TERM_COUNTS_DF[~IS_ENGLISH_MASK].sort_values(\"word\")\n",
    "print(\"Total number of non english words:\", len(nonengl_terms_orig_pmi))\n",
    "\n",
    "print(\"Examples of words dropped due to being dubbed not english according to our procedure...\")\n",
    "print(\"-\", \"\\n- \".join(nonengl_terms_orig_pmi[\"word\"].values[::2000]))\n",
    "\n",
    "TERM_COUNTS_DF = TERM_COUNTS_DF[IS_ENGLISH_MASK]\n",
    "len(TERM_COUNTS_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db63a124",
   "metadata": {},
   "source": [
    "## Preprocess: Remove rare words\n",
    "\n",
    "Upon observation of the remaining words, we observe that some of the words in the list (e.g., \"succinylacetone\", \"clientage\") correspond to valid English words and, sometimes, typos. Since these words do not represent common English words, it could throw off our model during dataset generation (e.g., degrade generation, lack diversity). \n",
    "\n",
    "To account for this, we notice that these words are often rarer and occur less frequently in the dataset. As such, we decided to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13317ac4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cbelem/.conda/envs/py39/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/cbelem/.conda/envs/py39/lib/python3.9/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/cbelem/.conda/envs/py39/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/cbelem/.conda/envs/py39/lib/python3.9/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the term counts vs rank of english words\n",
    "sns.lineplot(x=np.arange(len(TERM_COUNTS_DF)), y=TERM_COUNTS_DF[\"counts\"].values)\n",
    "plt.xscale(\"log\"); plt.xlabel(\"Term rank\")\n",
    "plt.yscale(\"log\"); plt.ylabel(\"Term counts\")\n",
    "\n",
    "q = 0.3\n",
    "q_val = TERM_COUNTS_DF[\"counts\"].quantile(q)\n",
    "plt.axhline(q_val, label=f\"{q:.0%} quantile: {q_val}\", ls=\"--\", c=\"r\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cc7a362",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of low freq words: 45121\n",
      "Examples of words with higher rank (lower frequency):\n",
      "- girds\n",
      "- challengeable\n",
      "- signalization\n",
      "- suburbans\n",
      "- denslow\n",
      "- balloonists\n",
      "- charbroiled\n",
      "- yters\n",
      "- sallisaw\n",
      "- coffy\n",
      "- defibrillated\n",
      "- shaddoll\n",
      "- safex\n",
      "- spangly\n",
      "- cornewall\n",
      "- eigendirections\n",
      "- mpda\n",
      "- tectona\n",
      "- influenzas\n",
      "- flathub\n",
      "- nonkeratinized\n",
      "- ogromnym\n",
      "- spaning\n"
     ]
    }
   ],
   "source": [
    "low_freq_terms_alpha = TERM_COUNTS_DF[TERM_COUNTS_DF[\"counts\"] < q_val].sort_values(\"counts\", ascending=False)\n",
    "print(\"Total number of low freq words:\", len(low_freq_terms_alpha))\n",
    "\n",
    "print(\"Examples of words with higher rank (lower frequency):\")\n",
    "print(\"-\", \"\\n- \".join(low_freq_terms_alpha[\"word\"].values[::2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c2a7994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>counts</th>\n",
       "      <th>freq</th>\n",
       "      <th>isalpha</th>\n",
       "      <th>ft_pred_lang</th>\n",
       "      <th>ft_pred_conf</th>\n",
       "      <th>wordnet_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>376680</th>\n",
       "      <td>distributively</td>\n",
       "      <td>5610</td>\n",
       "      <td>4.325245e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>0.778595</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376699</th>\n",
       "      <td>networkmode</td>\n",
       "      <td>5610</td>\n",
       "      <td>4.325245e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>0.724172</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376747</th>\n",
       "      <td>cutline</td>\n",
       "      <td>5608</td>\n",
       "      <td>4.323703e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>0.845637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376750</th>\n",
       "      <td>jham</td>\n",
       "      <td>5608</td>\n",
       "      <td>4.323703e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>0.717699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376754</th>\n",
       "      <td>mismanage</td>\n",
       "      <td>5608</td>\n",
       "      <td>4.323703e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>es</td>\n",
       "      <td>0.328606</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376759</th>\n",
       "      <td>imro</td>\n",
       "      <td>5608</td>\n",
       "      <td>4.323703e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>0.947572</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376770</th>\n",
       "      <td>oneill</td>\n",
       "      <td>5608</td>\n",
       "      <td>4.323703e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>0.646695</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376771</th>\n",
       "      <td>minelaying</td>\n",
       "      <td>5608</td>\n",
       "      <td>4.323703e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>0.799603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376774</th>\n",
       "      <td>driveinfo</td>\n",
       "      <td>5608</td>\n",
       "      <td>4.323703e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>0.816889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376776</th>\n",
       "      <td>buccally</td>\n",
       "      <td>5608</td>\n",
       "      <td>4.323703e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>0.725402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376780</th>\n",
       "      <td>loyalism</td>\n",
       "      <td>5608</td>\n",
       "      <td>4.323703e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>0.734118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376783</th>\n",
       "      <td>selectionset</td>\n",
       "      <td>5608</td>\n",
       "      <td>4.323703e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>0.861329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376799</th>\n",
       "      <td>penology</td>\n",
       "      <td>5607</td>\n",
       "      <td>4.322932e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>0.356879</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376806</th>\n",
       "      <td>glossitis</td>\n",
       "      <td>5607</td>\n",
       "      <td>4.322932e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>war</td>\n",
       "      <td>0.280621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376807</th>\n",
       "      <td>invalidfield</td>\n",
       "      <td>5607</td>\n",
       "      <td>4.322932e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>0.616966</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376809</th>\n",
       "      <td>umbilicate</td>\n",
       "      <td>5607</td>\n",
       "      <td>4.322932e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>0.373792</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376838</th>\n",
       "      <td>dfes</td>\n",
       "      <td>5606</td>\n",
       "      <td>4.322161e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>0.878299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376844</th>\n",
       "      <td>jasminum</td>\n",
       "      <td>5606</td>\n",
       "      <td>4.322161e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>0.151966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376874</th>\n",
       "      <td>preventives</td>\n",
       "      <td>5606</td>\n",
       "      <td>4.322161e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>0.745604</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376878</th>\n",
       "      <td>widelands</td>\n",
       "      <td>5606</td>\n",
       "      <td>4.322161e-08</td>\n",
       "      <td>True</td>\n",
       "      <td>en</td>\n",
       "      <td>0.619191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  word  counts          freq  isalpha ft_pred_lang  \\\n",
       "376680  distributively    5610  4.325245e-08     True           en   \n",
       "376699     networkmode    5610  4.325245e-08     True           en   \n",
       "376747         cutline    5608  4.323703e-08     True           en   \n",
       "376750            jham    5608  4.323703e-08     True           en   \n",
       "376754       mismanage    5608  4.323703e-08     True           es   \n",
       "376759            imro    5608  4.323703e-08     True           en   \n",
       "376770          oneill    5608  4.323703e-08     True           en   \n",
       "376771      minelaying    5608  4.323703e-08     True           en   \n",
       "376774       driveinfo    5608  4.323703e-08     True           en   \n",
       "376776        buccally    5608  4.323703e-08     True           en   \n",
       "376780        loyalism    5608  4.323703e-08     True           en   \n",
       "376783    selectionset    5608  4.323703e-08     True           en   \n",
       "376799        penology    5607  4.322932e-08     True           en   \n",
       "376806       glossitis    5607  4.322932e-08     True          war   \n",
       "376807    invalidfield    5607  4.322932e-08     True           en   \n",
       "376809      umbilicate    5607  4.322932e-08     True           en   \n",
       "376838            dfes    5606  4.322161e-08     True           en   \n",
       "376844        jasminum    5606  4.322161e-08     True           en   \n",
       "376874     preventives    5606  4.322161e-08     True           en   \n",
       "376878       widelands    5606  4.322161e-08     True           en   \n",
       "\n",
       "        ft_pred_conf  wordnet_counts  \n",
       "376680      0.778595               2  \n",
       "376699      0.724172               0  \n",
       "376747      0.845637               0  \n",
       "376750      0.717699               0  \n",
       "376754      0.328606               1  \n",
       "376759      0.947572               0  \n",
       "376770      0.646695               0  \n",
       "376771      0.799603               1  \n",
       "376774      0.816889               0  \n",
       "376776      0.725402               0  \n",
       "376780      0.734118               0  \n",
       "376783      0.861329               0  \n",
       "376799      0.356879               1  \n",
       "376806      0.280621               1  \n",
       "376807      0.616966               0  \n",
       "376809      0.373792               1  \n",
       "376838      0.878299               0  \n",
       "376844      0.151966               1  \n",
       "376874      0.745604               3  \n",
       "376878      0.619191               0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TERM_COUNTS_DF = TERM_COUNTS_DF[TERM_COUNTS_DF[\"counts\"] > q_val]\n",
    "TERM_COUNTS_DF.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6676e551",
   "metadata": {},
   "source": [
    "`TERM_COUNTS_DF` contains the information about a good estimate the English terms that are likely to occur in the data. A few limitations that we should address in the future are:\n",
    "\n",
    "1. remove slang (e.g., making use of [SlangNet](https://aclanthology.org/L16-1686/), [SlangSD](http://liangwu.me/slangsd/), etc.\n",
    "2. remove names\n",
    "3. remove abbreviations\n",
    "\n",
    "\n",
    "For now, we will proceed, assuming this is the best subset of the English words we can derive from PILE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303118fa",
   "metadata": {},
   "source": [
    "## Computing the PMI for each word\n",
    "\n",
    "In this section, we will compute the $\\texttt{PMIDiff}(w)$ for every word $w$. To that end, we will first define a list of gendered words (eg, \"mother\", \"father\", \"boy\", \"girl\") and we will compute the $\\texttt{PMI}$ of every word and these _group words_. Note that the co-occurrence counts loaded in `TERMS_CO_OCCUR`, consist of counts within a window size 10 after stop words have been removed. These do not refer to co-occurrence counts within the same document. \n",
    "\n",
    "$$\\texttt{PMI}(w, g) = log \\frac{p(w, g)}{p(w)p(g)}$$, where $w$ is the word in the vocabullary and $g$ is a group word. PMI therefore represents the strength of association between the two words, namely, how likely are the two words to co-occur together when compared to appearing individually. A negative value indicates that the words are less likely to co-occur together, whereas a positive value implies that the words almost always appear together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a96e7dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fe3b079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file at /extra/ucinlp1/cbelem/bias-dataset-project/all_co_words.pkl\n",
      "Time to read file 1.18 min\n",
      "Number of bigrams: 131889277\n",
      "Reduced number of bigrams: 113310272\n"
     ]
    }
   ],
   "source": [
    "# This document is huge\n",
    "TERMS_CO_OCCUR = read_original_coccurrence_files(DATA_DIR)\n",
    "print(\"Number of bigrams:\", len(TERMS_CO_OCCUR))\n",
    "TERMS_CO_OCCUR_TOTAL = sum(TERMS_CO_OCCUR.values()) # 131M\n",
    "\n",
    "\n",
    "GROUP_TERMS = [\n",
    "    (\"she\", \"he\"),\n",
    "    (\"her\", \"his\"),\n",
    "    (\"her\", \"him\"),\n",
    "    (\"hers\", \"his\"),\n",
    "    (\"herself\", \"himself\"),\n",
    "    (\"grandmother\", \"grandfather\"),\n",
    "    (\"grandma\", \"grandpa\"),\n",
    "    (\"stepmother\", \"stepfather\"),\n",
    "    (\"stepmom\", \"stepdad\"),\n",
    "    (\"mother\", \"father\"),\n",
    "    (\"mom\", \"dad\"),\n",
    "    (\"aunt\", \"uncle\"),\n",
    "    (\"aunts\", \"uncles\"),\n",
    "    (\"mummy\", \"daddy\"),\n",
    "    (\"sister\", \"brother\"),\n",
    "    (\"sisters\", \"brothers\"),\n",
    "    (\"daughter\", \"son\"),\n",
    "    (\"daughters\", \"sons\"),\n",
    "    (\"female\", \"male\"),\n",
    "    (\"females\", \"males\"),\n",
    "    (\"feminine\", \"masculine\"),\n",
    "    (\"woman\", \"man\"),\n",
    "    (\"women\", \"men\"),\n",
    "    (\"madam\", \"sir\"),\n",
    "    (\"matriarchy\", \"patriarchy\"),\n",
    "    (\"girl\", \"boy\"),\n",
    "    (\"lass\", \"lad\"),\n",
    "    (\"girls\", \"boys\"),\n",
    "    (\"girlfriend\", \"boyfriend\"),\n",
    "    (\"girlfriends\", \"boyfriends\"),\n",
    "    (\"wife\", \"husband\"),\n",
    "    (\"wives\", \"husbands\"),\n",
    "    (\"queen\", \"king\"),\n",
    "    (\"queens\", \"kings\"),\n",
    "    (\"princess\", \"prince\"),\n",
    "    (\"princesses\", \"princes\"),\n",
    "    (\"lady\", \"lord\"),\n",
    "    (\"ladies\", \"lords\"),\n",
    "]\n",
    "FEMALE_TERMS, MALE_TERMS = zip(*GROUP_TERMS)\n",
    "\n",
    "ALL_TERMS = set(TERM_COUNTS_DF.word.values)\n",
    "ALL_TERMS.add(FEMALE_TERMS)\n",
    "ALL_TERMS.add(MALE_TERMS)\n",
    "\n",
    "# Since we're interested in computing the PMI value for every word and other K words\n",
    "# we will have to iterate it at least k times (which would be time consuming)\n",
    "# Therefore, we will filter out the structure to include only pairs where terms defined in \n",
    "# `terms` or group words appear.\n",
    "def select_subset(bigram_counts: dict, terms: set) -> dict:\n",
    "    results = {}\n",
    "    for bigram, counts in bigram_counts.items():\n",
    "        if bigram[0] in terms or bigram[1] in terms:\n",
    "            results[bigram] = counts       \n",
    "    return results\n",
    "\n",
    "\n",
    "# Update term counts dict to contain only the relevant terms\n",
    "TERM_COUNTS_DICT = {w: v for w, v in TERM_COUNTS_DICT.items() if w in ALL_TERMS}\n",
    "len(TERM_COUNTS_DICT), len(TERM_COUNTS_DF)\n",
    "\n",
    "# Update terms co-occurs\n",
    "TERMS_CO_OCCUR = select_subset(TERMS_CO_OCCUR, ALL_TERMS)\n",
    "print(\"Reduced number of bigrams:\", len(TERMS_CO_OCCUR)) # roughly 113M pairs remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25a6bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pmi(unigram_counts: dict, bigram_counts: dict, w, g, unigram_total: int, bigram_total: int):\n",
    "    \"\"\"Compute PMI for a words w, g using the bigram and unigram counts structures.\"\"\"\n",
    "    p_w = unigram_counts.get(w, 0) / unigram_total\n",
    "    p_g = unigram_counts.get(g, 0) / unigram_total\n",
    "    \n",
    "    p_w_g = bigram_counts.get((w, g), 0) + bigram_counts.get((g, w), 0) / bigram_total\n",
    "    \n",
    "    if 0 in (p_w, p_g, p_w_g):\n",
    "        return None\n",
    "    \n",
    "    # For numerical stability, we opt for computing PMI as:\n",
    "    return np.log(p_w_g) - np.log(p_w) - np.log(p_g)\n",
    "\n",
    "\n",
    "def compute_pmi_per_group_word(words: List[str], group_words: List[str]):\n",
    "    results = defaultdict(list)\n",
    "    for group_word in set(group_words):\n",
    "        for word in words:\n",
    "            pmi = compute_pmi(\n",
    "                unigram_counts=TERM_COUNTS_DICT,\n",
    "                bigram_counts=TERMS_CO_OCCUR,\n",
    "                w=word, g=group_word,\n",
    "                unigram_total=TERM_COUNTS_TOTAL, \n",
    "                bigram_total=TERMS_CO_OCCUR_TOTAL)\n",
    "            \n",
    "            results[f\"pmi_{group_word}\"].append(pmi)\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45c2ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the PMI between every word and every female word\n",
    "PMI_FEMALE = compute_pmi_per_group_word(TERM_COUNTS_DF[\"word\"].values.tolist(), FEMALE_TERMS)\n",
    "\n",
    "# Compute the PMI between every word and every male word\n",
    "PMI_MALE = compute_pmi_per_group_word(TERM_COUNTS_DF[\"word\"].values.tolist(), MALE_TERMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e28453ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 37)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PMI_FEMALE), len(PMI_MALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7b39d5",
   "metadata": {},
   "source": [
    "### Computing the PMI difference:\n",
    "\n",
    "To obtain a sense of how much more likely is a word to co-occur with female words than with male words, we can compute the difference of PMIs as follows:\n",
    "\n",
    "$$\\texttt{PMIDiff}(w, g_F, g_M) = \\texttt{PMI}(w, g_F) - \\texttt{PMI}(w, g_M)$$, where $g_M$ and $g_F$ represent male and female gendered words, respectively.\n",
    "\n",
    "In the original versions of this work, we simply determined the gendered co-occurrence of a word by computing $\\texttt{PMIDiff}(w, \\texttt{\"she\"}, \\texttt{\"he\"})$. However, this may be suboptimal since many other words can be implicitly correlated with gender. \n",
    "\n",
    "In this notebook, we will compute the PMI difference as the $max_{(g_F, g_M) \\in (G_F, G_M)} |\\texttt{PMIDiff}(w, g_F, g_M)|$, where $(G_F, G_M)$ is the list of paired group words (eg, as defined in `GROUP_TERMS`). The intuition is that we will represent the gender polarity of a word with the strongest existing correlation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0a97e9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105296 entries, 0 to 105295\n",
      "Data columns (total 39 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   word                         105296 non-null  object \n",
      " 1   pmi_she_he                   54302 non-null   float64\n",
      " 2   pmi_her_his                  58880 non-null   float64\n",
      " 3   pmi_her_him                  51824 non-null   float64\n",
      " 4   pmi_hers_his                 0 non-null       object \n",
      " 5   pmi_herself_himself          0 non-null       object \n",
      " 6   pmi_grandmother_grandfather  5870 non-null    float64\n",
      " 7   pmi_grandma_grandpa          1022 non-null    float64\n",
      " 8   pmi_stepmother_stepfather    1002 non-null    float64\n",
      " 9   pmi_stepmom_stepdad          0 non-null       object \n",
      " 10  pmi_mother_father            24598 non-null   float64\n",
      " 11  pmi_mom_dad                  8761 non-null    float64\n",
      " 12  pmi_aunt_uncle               5173 non-null    float64\n",
      " 13  pmi_aunts_uncles             885 non-null     float64\n",
      " 14  pmi_mummy_daddy              1211 non-null    float64\n",
      " 15  pmi_sister_brother           14963 non-null   float64\n",
      " 16  pmi_sisters_brothers         7658 non-null    float64\n",
      " 17  pmi_daughter_son             17402 non-null   float64\n",
      " 18  pmi_daughters_sons           6881 non-null    float64\n",
      " 19  pmi_female_male              23602 non-null   float64\n",
      " 20  pmi_females_males            11295 non-null   float64\n",
      " 21  pmi_feminine_masculine       4319 non-null    float64\n",
      " 22  pmi_woman_man                30009 non-null   float64\n",
      " 23  pmi_women_men                33197 non-null   float64\n",
      " 24  pmi_madam_sir                1488 non-null    float64\n",
      " 25  pmi_matriarchy_patriarchy    54 non-null      float64\n",
      " 26  pmi_girl_boy                 20199 non-null   float64\n",
      " 27  pmi_lass_lad                 858 non-null     float64\n",
      " 28  pmi_girls_boys               16891 non-null   float64\n",
      " 29  pmi_girlfriend_boyfriend     5718 non-null    float64\n",
      " 30  pmi_girlfriends_boyfriends   1066 non-null    float64\n",
      " 31  pmi_wife_husband             19109 non-null   float64\n",
      " 32  pmi_wives_husbands           4393 non-null    float64\n",
      " 33  pmi_queen_king               9089 non-null    float64\n",
      " 34  pmi_queens_kings             2571 non-null    float64\n",
      " 35  pmi_princess_prince          4692 non-null    float64\n",
      " 36  pmi_princesses_princes       1053 non-null    float64\n",
      " 37  pmi_lady_lord                6646 non-null    float64\n",
      " 38  pmi_ladies_lords             3074 non-null    float64\n",
      "dtypes: float64(35), object(4)\n",
      "memory usage: 31.3+ MB\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "# Every word w, we have len(GROUP_TERMS) PMI values\n",
    "# - some of which can be None, if one of the grouped words did not occur with w)\n",
    "results = defaultdict(list)\n",
    "results[\"word\"] = TERM_COUNTS_DF[\"word\"].values.tolist()\n",
    "\n",
    "for word_idx in range(len(TERM_COUNTS_DF)):\n",
    "    for fterm, mterm in GROUP_TERMS:\n",
    "        pmi_f = PMI_FEMALE[f\"pmi_{fterm}\"][word_idx]\n",
    "        pmi_m = PMI_MALE[f\"pmi_{mterm}\"][word_idx]\n",
    "        \n",
    "        # If one of the terms is not defined, append None\n",
    "        if pmi_f is None or pmi_m is None or math.isnan(pmi_f) or math.isnan(pmi_m):\n",
    "            results[f\"pmi_{fterm}_{mterm}\"].append(None)\n",
    "        else:\n",
    "            results[f\"pmi_{fterm}_{mterm}\"].append(pmi_f - pmi_m)\n",
    "            \n",
    "            \n",
    "results = pd.DataFrame(results)\n",
    "results.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c3f163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a28eb2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pmi_she_he</th>\n",
       "      <th>pmi_her_his</th>\n",
       "      <th>pmi_her_him</th>\n",
       "      <th>pmi_hers_his</th>\n",
       "      <th>pmi_herself_himself</th>\n",
       "      <th>pmi_grandmother_grandfather</th>\n",
       "      <th>pmi_grandma_grandpa</th>\n",
       "      <th>pmi_stepmother_stepfather</th>\n",
       "      <th>pmi_stepmom_stepdad</th>\n",
       "      <th>...</th>\n",
       "      <th>pmi_girlfriend_boyfriend</th>\n",
       "      <th>pmi_girlfriends_boyfriends</th>\n",
       "      <th>pmi_wife_husband</th>\n",
       "      <th>pmi_wives_husbands</th>\n",
       "      <th>pmi_queen_king</th>\n",
       "      <th>pmi_queens_kings</th>\n",
       "      <th>pmi_princess_prince</th>\n",
       "      <th>pmi_princesses_princes</th>\n",
       "      <th>pmi_lady_lord</th>\n",
       "      <th>pmi_ladies_lords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>he</td>\n",
       "      <td>-0.265558</td>\n",
       "      <td>-0.865963</td>\n",
       "      <td>-0.722650</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.608781</td>\n",
       "      <td>-0.879060</td>\n",
       "      <td>-0.591373</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382008</td>\n",
       "      <td>0.768178</td>\n",
       "      <td>0.703848</td>\n",
       "      <td>0.993050</td>\n",
       "      <td>-0.915364</td>\n",
       "      <td>-0.925902</td>\n",
       "      <td>-0.255627</td>\n",
       "      <td>-0.464170</td>\n",
       "      <td>0.958814</td>\n",
       "      <td>0.488122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>his</td>\n",
       "      <td>24.393786</td>\n",
       "      <td>-26.205727</td>\n",
       "      <td>-0.867249</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.558500</td>\n",
       "      <td>-0.471417</td>\n",
       "      <td>-0.327862</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1.934905</td>\n",
       "      <td>1.380073</td>\n",
       "      <td>2.387322</td>\n",
       "      <td>2.297434</td>\n",
       "      <td>-0.663874</td>\n",
       "      <td>-0.654000</td>\n",
       "      <td>-0.573947</td>\n",
       "      <td>-0.729233</td>\n",
       "      <td>0.711715</td>\n",
       "      <td>-0.203620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>her</td>\n",
       "      <td>27.794594</td>\n",
       "      <td>1.082642</td>\n",
       "      <td>0.779209</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.778857</td>\n",
       "      <td>0.849701</td>\n",
       "      <td>0.135938</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.720319</td>\n",
       "      <td>-0.387546</td>\n",
       "      <td>-2.343299</td>\n",
       "      <td>-1.324431</td>\n",
       "      <td>1.592257</td>\n",
       "      <td>0.375076</td>\n",
       "      <td>1.338525</td>\n",
       "      <td>0.692578</td>\n",
       "      <td>2.248230</td>\n",
       "      <td>1.420042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she</td>\n",
       "      <td>27.227379</td>\n",
       "      <td>2.534845</td>\n",
       "      <td>0.903386</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.173369</td>\n",
       "      <td>1.235702</td>\n",
       "      <td>0.532250</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.500973</td>\n",
       "      <td>-0.623451</td>\n",
       "      <td>25.219580</td>\n",
       "      <td>25.431784</td>\n",
       "      <td>1.655895</td>\n",
       "      <td>0.731248</td>\n",
       "      <td>1.563366</td>\n",
       "      <td>1.240706</td>\n",
       "      <td>2.309701</td>\n",
       "      <td>1.388678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time</td>\n",
       "      <td>-0.018094</td>\n",
       "      <td>-0.075418</td>\n",
       "      <td>-0.024359</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.032290</td>\n",
       "      <td>0.138998</td>\n",
       "      <td>-0.094809</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102838</td>\n",
       "      <td>0.189910</td>\n",
       "      <td>25.979100</td>\n",
       "      <td>25.974651</td>\n",
       "      <td>-0.229606</td>\n",
       "      <td>-0.575594</td>\n",
       "      <td>0.405374</td>\n",
       "      <td>0.184908</td>\n",
       "      <td>1.479240</td>\n",
       "      <td>0.666625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105291</th>\n",
       "      <td>umbilicate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105292</th>\n",
       "      <td>dfes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105293</th>\n",
       "      <td>jasminum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105294</th>\n",
       "      <td>preventives</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105295</th>\n",
       "      <td>widelands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105296 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  pmi_she_he  pmi_her_his  pmi_her_him pmi_hers_his  \\\n",
       "0                he   -0.265558    -0.865963    -0.722650         None   \n",
       "1               his   24.393786   -26.205727    -0.867249         None   \n",
       "2               her   27.794594     1.082642     0.779209         None   \n",
       "3               she   27.227379     2.534845     0.903386         None   \n",
       "4              time   -0.018094    -0.075418    -0.024359         None   \n",
       "...             ...         ...          ...          ...          ...   \n",
       "105291   umbilicate         NaN          NaN          NaN         None   \n",
       "105292         dfes         NaN          NaN          NaN         None   \n",
       "105293     jasminum         NaN          NaN          NaN         None   \n",
       "105294  preventives         NaN          NaN          NaN         None   \n",
       "105295    widelands         NaN          NaN          NaN         None   \n",
       "\n",
       "       pmi_herself_himself  pmi_grandmother_grandfather  pmi_grandma_grandpa  \\\n",
       "0                     None                    -0.608781            -0.879060   \n",
       "1                     None                    -0.558500            -0.471417   \n",
       "2                     None                     0.778857             0.849701   \n",
       "3                     None                     1.173369             1.235702   \n",
       "4                     None                    -0.032290             0.138998   \n",
       "...                    ...                          ...                  ...   \n",
       "105291                None                          NaN                  NaN   \n",
       "105292                None                          NaN                  NaN   \n",
       "105293                None                          NaN                  NaN   \n",
       "105294                None                          NaN                  NaN   \n",
       "105295                None                          NaN                  NaN   \n",
       "\n",
       "        pmi_stepmother_stepfather pmi_stepmom_stepdad  ...  \\\n",
       "0                       -0.591373                None  ...   \n",
       "1                       -0.327862                None  ...   \n",
       "2                        0.135938                None  ...   \n",
       "3                        0.532250                None  ...   \n",
       "4                       -0.094809                None  ...   \n",
       "...                           ...                 ...  ...   \n",
       "105291                        NaN                None  ...   \n",
       "105292                        NaN                None  ...   \n",
       "105293                        NaN                None  ...   \n",
       "105294                        NaN                None  ...   \n",
       "105295                        NaN                None  ...   \n",
       "\n",
       "        pmi_girlfriend_boyfriend  pmi_girlfriends_boyfriends  \\\n",
       "0                       0.382008                    0.768178   \n",
       "1                       1.934905                    1.380073   \n",
       "2                      -1.720319                   -0.387546   \n",
       "3                      -0.500973                   -0.623451   \n",
       "4                       0.102838                    0.189910   \n",
       "...                          ...                         ...   \n",
       "105291                       NaN                         NaN   \n",
       "105292                       NaN                         NaN   \n",
       "105293                       NaN                         NaN   \n",
       "105294                       NaN                         NaN   \n",
       "105295                       NaN                         NaN   \n",
       "\n",
       "        pmi_wife_husband  pmi_wives_husbands  pmi_queen_king  \\\n",
       "0               0.703848            0.993050       -0.915364   \n",
       "1               2.387322            2.297434       -0.663874   \n",
       "2              -2.343299           -1.324431        1.592257   \n",
       "3              25.219580           25.431784        1.655895   \n",
       "4              25.979100           25.974651       -0.229606   \n",
       "...                  ...                 ...             ...   \n",
       "105291               NaN                 NaN             NaN   \n",
       "105292               NaN                 NaN             NaN   \n",
       "105293               NaN                 NaN             NaN   \n",
       "105294               NaN                 NaN             NaN   \n",
       "105295               NaN                 NaN             NaN   \n",
       "\n",
       "        pmi_queens_kings  pmi_princess_prince  pmi_princesses_princes  \\\n",
       "0              -0.925902            -0.255627               -0.464170   \n",
       "1              -0.654000            -0.573947               -0.729233   \n",
       "2               0.375076             1.338525                0.692578   \n",
       "3               0.731248             1.563366                1.240706   \n",
       "4              -0.575594             0.405374                0.184908   \n",
       "...                  ...                  ...                     ...   \n",
       "105291               NaN                  NaN                     NaN   \n",
       "105292               NaN                  NaN                     NaN   \n",
       "105293               NaN                  NaN                     NaN   \n",
       "105294               NaN                  NaN                     NaN   \n",
       "105295               NaN                  NaN                     NaN   \n",
       "\n",
       "        pmi_lady_lord  pmi_ladies_lords  \n",
       "0            0.958814          0.488122  \n",
       "1            0.711715         -0.203620  \n",
       "2            2.248230          1.420042  \n",
       "3            2.309701          1.388678  \n",
       "4            1.479240          0.666625  \n",
       "...               ...               ...  \n",
       "105291            NaN               NaN  \n",
       "105292            NaN               NaN  \n",
       "105293            NaN               NaN  \n",
       "105294            NaN               NaN  \n",
       "105295            NaN               NaN  \n",
       "\n",
       "[105296 rows x 39 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01357526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4f6c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d21cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89a6bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370ac111",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_PMI_DF = read_pmi_diff(\"../data/pmi-diffs-gender.txt\")\n",
    "ORIG_PMI_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_PMI_DF = ORIG_PMI_DF.set_index(\"word\").join(TERM_COUNTS_DF.set_index(\"word\"), how=\"left\")\n",
    "ORIG_PMI_DF = ORIG_PMI_DF.reset_index()\n",
    "ORIG_PMI_DF.drop(\"word\", axis=1).corr(\"kendall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ee668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(ORIG_PMI_DF, y=\"freq\", x=\"pmi_diff\", s=5, alpha=0.5)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee013b69",
   "metadata": {},
   "source": [
    "### Drop uncommon words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b2dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark the most common words\n",
    "ORIG_PMI_DF[\"is_common\"] = ORIG_PMI_DF[\"word\"].isin(TERM_COUNTS_DF_ALPHA_UQ[\"word\"].values)\n",
    "ORIG_PMI_DF[\"is_common\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec646485",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_freq_terms_orig_pmi = ORIG_PMI_DF[ORIG_PMI_DF[\"is_common\"] == False].sort_values(\"word\")\n",
    "print(\"Total number of low freq words:\", len(low_freq_terms_orig_pmi))\n",
    "\n",
    "print(\"Examples of words dropped due to lower frequency:\")\n",
    "print(\"-\", \"\\n- \".join(low_freq_terms_orig_pmi[\"word\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949dbbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3), dpi=200)\n",
    "sns.histplot(ORIG_PMI_DF, x=\"pmi_diff\", hue=\"is_common\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c385ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_PMI_DF_UQ = ORIG_PMI_DF[ORIG_PMI_DF[\"is_common\"]].reset_index(drop=True)\n",
    "print(len(ORIG_PMI_DF), \"-->\", len(ORIG_PMI_DF_UQ), \"; delta =\", len(ORIG_PMI_DF)-len(ORIG_PMI_DF_UQ))\n",
    "ORIG_PMI_DF_UQ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442d37ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_PMI_DF_UQ.drop(\"word\", axis=1).corr(\"kendall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a7361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_PMI_DF_UQ_LANG[mask].sort_values(\"word\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7090095",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_PMI_DF_UQ_ENG = ORIG_PMI_DF_UQ_LANG[mask]\n",
    "ORIG_PMI_DF_UQ_ENG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fca574",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(ORIG_PMI_DF_UQ_LANG, x=\"pred_conf\", y=\"wordnet_counts\", hue=\"is_english\", s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa753df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(ORIG_PMI_DF_UQ_LANG, x=\"pred_conf\", y=\"wordnet_counts\", hue=\"is_english\", s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23775eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(ORIG_PMI_DF_UQ_ENG, x=\"pred_conf\", y=\"pmi_diff\", hue=\"is_english\", s=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e11c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3), dpi=200)\n",
    "sns.jointplot(ORIG_PMI_DF_UQ_ENG, x=\"wordnet_counts\", y=\"pmi_diff\", s=5)\n",
    "plt.xlabel(\"Number of WordNet definitions\")\n",
    "plt.ylabel(\"PMI Difference, $\\delta(w)$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f56df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TERM_COUNTS_DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c641e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_PMI_DF_UQ_ENG.shape[0], TERM_COUNTS_DF.shape[0], round(ORIG_PMI_DF_UQ_ENG.shape[0] / TERM_COUNTS_DF.shape[0], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fd5e1b",
   "metadata": {},
   "source": [
    "### Obtain the words\n",
    "\n",
    "In the variable ORIG_PMI_DF_UQ_ENG, we have the selected English words.\n",
    "We have yet to reduce the set of words to the ones having the same root.\n",
    "Since we're using stratified sampling to select one word from each bin, we do not need to care too much about this. If two words with the same root are selected, it is likely that it is because they were sampled from different bins. In which case, it may suggest that there is a significant difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed7451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 20\n",
    "# define PMI range\n",
    "pmi_diff_max = ORIG_PMI_DF_UQ_ENG[\"pmi_diff\"].apply(np.abs).describe()[\"max\"]\n",
    "print(pmi_diff_max)\n",
    "\n",
    "pmi_diff_max = np.ceil(pmi_diff_max)\n",
    "bins = np.linspace(-pmi_diff_max, pmi_diff_max, num_bins)\n",
    "\n",
    "ORIG_PMI_DF_UQ_ENG.loc[:,\"pmi_diff_bins\"] = pd.cut(ORIG_PMI_DF_UQ_ENG[\"pmi_diff\"], bins)\n",
    "ORIG_PMI_DF_UQ_ENG[\"pmi_diff_bins\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94928f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = sorted(ORIG_PMI_DF_UQ_ENG[\"pmi_diff_bins\"].unique())\n",
    "interval_idx_middle = [ix for ix, interval in enumerate(intervals) if 0 in interval][0]\n",
    "intervals[interval_idx_middle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67986b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_bin = ORIG_PMI_DF_UQ_ENG[ORIG_PMI_DF_UQ_ENG[\"pmi_diff_bins\"] == intervals[interval_idx_middle]]\n",
    "sampling_bin = sampling_bin.sort_values(\"freq\", ascending=False)\n",
    "sampling_bin.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd4b5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_bin.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d88697",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_bin.sort_values(\"pmi_diff\").head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4aa8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_bin.sort_values(\"pmi_diff\").tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee50a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_PMI_DF_UQ_ENG[\"skews\"] = [\"male\"] * len(ORIG_PMI_DF_UQ_ENG)\n",
    "female_mask = ORIG_PMI_DF_UQ_ENG[\"pmi_diff\"] > 0\n",
    "ORIG_PMI_DF_UQ_ENG.loc[female_mask, \"skews\"] = \"female\"\n",
    "\n",
    "neutral_mask = (ORIG_PMI_DF_UQ_ENG[\"pmi_diff\"] >= -0.263) & (ORIG_PMI_DF_UQ_ENG[\"pmi_diff\"] <= 0.263)\n",
    "ORIG_PMI_DF_UQ_ENG.loc[neutral_mask, \"skews\"] = \"neutral\"\n",
    "\n",
    "ORIG_PMI_DF_UQ_ENG[\"skews\"].value_counts() / len(ORIG_PMI_DF_UQ_ENG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb395a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_PMI_DF_UQ_ENG.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cc1aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_info(df: pd.DataFrame):\n",
    "    results = []\n",
    "    for ix, row in df.iterrows():\n",
    "        wordnet_defs = {}\n",
    "        \n",
    "        if row[\"wordnet_counts\"] > 0:\n",
    "            synsets = wordnet.synsets(row[\"word\"])\n",
    "            wordnet_defs = {s.name(): s.definition() for s in synsets}\n",
    "            \n",
    "        results.append(wordnet_defs)\n",
    "        \n",
    "    return results\n",
    "\n",
    "\n",
    "wordnet_sample = get_wordnet_info(ORIG_PMI_DF_UQ_ENG)\n",
    "ORIG_PMI_DF_UQ_ENG[\"wordnet_definitions\"] = wordnet_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a43763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_PMI_DF_UQ_ENG.to_csv(\"../results__pool_of_words_by_pmi.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c3ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_PMI_DF_UQ_ENG_NEUTRAL = ORIG_PMI_DF_UQ_ENG[ORIG_PMI_DF_UQ_ENG[\"skews\"] == \"neutral\"].copy()\n",
    "ORIG_PMI_DF_UQ_ENG_NEUTRAL.to_csv(\"../results__neutral__pool_of_words_by_pmi.csv\", index=None)\n",
    "len(ORIG_PMI_DF_UQ_ENG_NEUTRAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8579d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "BASE_DIR = \"\"\n",
    "SAMPLES = []\n",
    "for i, seed in enumerate((9123, 19223, 8172361, 91283, 72613)):\n",
    "    sample = ORIG_PMI_DF_UQ_ENG_NEUTRAL.sample(n=100, replace=False, random_state=seed)\n",
    "    \n",
    "    for num in (5, 10, 20):\n",
    "        os.makedirs(f\"../results-words{num}/words{i+1}\", exist_ok=True)\n",
    "        sample.to_csv(f\"../results-words{num}/words{i+1}/selected_words__{seed}.csv\")\n",
    "        words = sorted(sample[\"word\"].unique())\n",
    "\n",
    "        with open(f\"../results-words{num}/words{i+1}/words.txt\", \"w\") as f:\n",
    "            f.write(\"\\n\".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe70194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91797449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c310979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c959cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ORIG_PMI_DF_UQ_ENG.groupby('pmi_diff_bins', group_keys=False).apply(lambda x: x.sample(frac=0.005))\n",
    "sample[\"skews\"].value_counts() / len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b841ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"pmi_diff_bins\"].value_counts() / len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7aab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "sns.histplot(ORIG_PMI_DF_UQ_ENG, x=\"pmi_diff\", binwidth=0.1, ax=ax, label=f\"Original: {len(ORIG_PMI_DF_UQ_ENG)}\", stat=\"probability\")\n",
    "sns.histplot(sample, x=\"pmi_diff\", binwidth=0.1, ax=ax, label=f\"Sample: {len(sample)}\", stat=\"probability\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ae4380",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2 = ORIG_PMI_DF_UQ_ENG.groupby('pmi_diff_bins', group_keys=False).apply(lambda x: x.sample(min(len(x), 10), replace=False))\n",
    "sample2[\"skews\"].value_counts() / len(sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f1b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "sns.histplot(ORIG_PMI_DF_UQ_ENG, x=\"pmi_diff\", binwidth=0.1, ax=ax, label=f\"Original: {len(ORIG_PMI_DF_UQ_ENG)}\", stat=\"probability\")\n",
    "sns.histplot(sample2, x=\"pmi_diff\", binwidth=0.1, ax=ax, label=f\"Sample: {len(sample2)}\", stat=\"probability\")\n",
    "plt.legend()\n",
    "sample2[\"pmi_diff_bins\"].value_counts() / len(sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2069703d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### add wordnet info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6310973a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e2386",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(sample2.word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7be892",
   "metadata": {},
   "source": [
    "### Persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21628272",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"../results/selected_words.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c884dbda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef562f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TERM_COUNTS_DICT[\"he\"],TERM_COUNTS_DICT[\"his\"], TERM_COUNTS_DICT[\"him\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a598df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TERM_COUNTS_DICT[\"she\"], TERM_COUNTS_DICT[\"her\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6862c831",
   "metadata": {},
   "source": [
    "# takes roughly 5 min, and will require 30GB of RAM\n",
    "TERMS_CO_OCCUR = read_original_coccurrence_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7a74db",
   "metadata": {},
   "source": [
    "In this file, we plan to select a set of words from the pretraining set in an automatic fashion. We'll try to make an intuitive choice by considering the following:\n",
    " \n",
    " $$\\text{PMI}(w, \\text{\"she\"}) - \\text{PMI}(w, \\text{\"he\"}) = log \\frac{P(\\text{\"she\"}|w)}{P(\\text{\"he\"}|w)}$$\n",
    "\n",
    "Thus, we will deem words whose odd ratio is 2.5 times smaller or larger to be unproprortionally skewed. We will not consider these words for our bias benchmark creation:\n",
    "- Remove words whose $\\frac{P(\\text{\"she\"}|w)}{P(\\text{\"he\"}|w)} \\geq \\tau \\vee \\frac{P(\\text{\"he\"}|w)}{P(\\text{\"she\"}|w)} \\geq \\tau$, where $\\tau = 2.5$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525d2dcc",
   "metadata": {},
   "source": [
    "## Check original words frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a2098",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df = pd.read_csv(\"../../experiments-tacl-june-2023/data/pmi_diffs_selected.csv\")\n",
    "# orig_df = orig_df[~orig_df[\"selected\"].isna()]\n",
    "\n",
    "orig_words_set = set(orig_df[\"word\"].unique())\n",
    "orig_df[\"is_common\"] = orig_df[\"word\"].isin(TERM_COUNTS_DF_ALPHA_UQ[\"word\"].values)\n",
    "orig_df[\"is_common\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50facf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=np.arange(len(TERM_COUNTS_DF_ALPHA)), y=TERM_COUNTS_DF_ALPHA[\"counts\"].values)\n",
    "\n",
    "idx = np.array(TERM_COUNTS_DF_ALPHA[TERM_COUNTS_DF_ALPHA[\"word\"].isin(orig_df[\"word\"])].index)\n",
    "sns.scatterplot(x=idx, y=TERM_COUNTS_DF_ALPHA[\"counts\"].values[idx], color=\"red\", s=15)\n",
    "plt.xscale(\"log\"); plt.xlabel(\"Term rank\")\n",
    "plt.yscale(\"log\"); plt.ylabel(\"Term counts\")\n",
    "\n",
    "q = 0.2\n",
    "q_val = TERM_COUNTS_DF_ALPHA[\"counts\"].quantile(q)\n",
    "plt.axhline(q_val, label=f\"{q:.0%} quantile: {q_val}\", ls=\"--\", c=\"r\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91d0852",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df = pd.read_csv(\"../../experiments-aug-2023/results/selected_words.csv\")\n",
    "current_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b145aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=np.arange(len(TERM_COUNTS_DF_ALPHA)), y=TERM_COUNTS_DF_ALPHA[\"counts\"].values)\n",
    "\n",
    "idx = np.array(TERM_COUNTS_DF_ALPHA[TERM_COUNTS_DF_ALPHA[\"word\"].isin(current_df[\"word\"])].index)\n",
    "sns.scatterplot(x=idx, y=TERM_COUNTS_DF_ALPHA[\"counts\"].values[idx], color=\"black\", s=15)\n",
    "plt.xscale(\"log\"); plt.xlabel(\"Term rank\")\n",
    "plt.yscale(\"log\"); plt.ylabel(\"Term counts\")\n",
    "\n",
    "q = 0.2\n",
    "q_val = TERM_COUNTS_DF_ALPHA[\"counts\"].quantile(q)\n",
    "plt.axhline(q_val, label=f\"{q:.0%} quantile: {q_val}\", ls=\"--\", c=\"r\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb867ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec225de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0c7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_PMI_DF_UQ_ENG.sort_values(\"counts\", ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a392f82b",
   "metadata": {},
   "source": [
    "## Originally picked words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e2885c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493\n"
     ]
    }
   ],
   "source": [
    "orig_words = pd.concat((\n",
    "    pd.read_csv(\"../results-words5/words1/selected_words__9123.csv\", index_col=0),\n",
    "    pd.read_csv(\"../results-words5/words2/selected_words__19223.csv\", index_col=0),\n",
    "    pd.read_csv(\"../results-words5/words3/selected_words__8172361.csv\", index_col=0),\n",
    "    pd.read_csv(\"../results-words5/words4/selected_words__91283.csv\", index_col=0),\n",
    "    pd.read_csv(\"../results-words5/words5/selected_words__72613.csv\", index_col=0),\n",
    ")).drop_duplicates()\n",
    "print(len(orig_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "04ae2f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_words.to_csv(\"selected_words.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a3891acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5605.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b2455",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_words[orig_words.word == \"whatcha\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ab7116",
   "metadata": {},
   "outputs": [],
   "source": [
    "TERM_COUNTS_DF[TERM_COUNTS_DF[\"wordnet_counts\"] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ed8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_words[orig_words.word.isin([\"votary\", \"wale\", \"waylaid\", \"waylay\", \"ween\", \"spasmodic\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea233611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
